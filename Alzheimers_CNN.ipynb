{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasonli999/Alzheimer-s_CNN/blob/main/Alzheimers_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRKpw_PdnWWl"
      },
      "source": [
        "Credit to sentdex and his Youtube PyTorch tutorials for the basic CNN Model that we adapted. All adapted sections are marked below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80MBHoe0n67W"
      },
      "source": [
        "Import Statements are below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m3s-Y1KlzJlI"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "-Rs5uKMTOlnA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import os \n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngytoICYoAC8"
      },
      "source": [
        "Checks to see if a GPU is available for the model to run on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EvIuhjmXW2l",
        "outputId": "bf501d5b-0779-40f5-d925-4d18498bfbfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device is: cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(f'Device is: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFULlcsEoLqP"
      },
      "source": [
        "Downloads and unzips the Kaggle dataset into the local directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a10SHADpMjZp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "!kaggle datasets download -d uraninjo/augmented-alzheimer-mri-dataset\n",
        "!unzip \"/content/augmented-alzheimer-mri-dataset.zip\"\n",
        "#downloads and unzips the dataset from Kaggle. Note that the kaggle.json API Token will need to be uploaded to the Colab for this to work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HCsv2KUoQ0T"
      },
      "source": [
        "folder_to_array() adapted from Sentdex. Functions to pre-process the data. folder_to_array() is mainly used in the model to turn the images into numpy arrays and to classify the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fgK5Avq5Ni9V"
      },
      "outputs": [],
      "source": [
        "\n",
        "def folder_to_csv(folder, classification, save = False):\n",
        "    \"\"\"Folder is a folder path, classification is the string classifiction. Save is a boolean\n",
        "    folder_to_csv() returns a csv with the path of the images in the first column and the classification in the second column\n",
        "    setting 'save' to true saves the csv to your drive with the name of the file as the name of the classification variable\"\"\"\n",
        "    file_names = []\n",
        "    for picture in os.listdir(folder):\n",
        "      path = os.path.join(folder, picture)\n",
        "      file_names.append([path, classification])\n",
        "      df = pd.DataFrame(file_names, columns = [\"File Path\", \"Classification\"])\n",
        "    if save == True:\n",
        "        name = f'{classification}.csv'\n",
        "        csv = df.to_csv(name, index = False)\n",
        "    return df.to_csv(index = False)\n",
        "\n",
        "def folder_to_array(folder, vectorlocation, image_size, save = False):\n",
        "    \"\"\"folder is a folder path, image_size is the image size of the post-processed picture, vectorlocation is the index of the one-hot vector\n",
        "    folder_to_array() returns all of the images in the folder specified into an 2d array with column1 as the image array and column2 as the\n",
        "    one-hot vector representing the data classification\"\"\"\n",
        "    training_data = []\n",
        "    for picture in tqdm(os.listdir(folder)):\n",
        "        if \"jpg\" in picture:\n",
        "            path = os.path.join(folder, picture)\n",
        "            img = cv2.imread(path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (image_size, image_size))\n",
        "            training_data.append([np.array(img), np.eye(4)[vectorlocation]]) #<- second index is the one-hot vector\n",
        "    training_data = np.array(training_data, list)\n",
        "    if save == True:\n",
        "        np.save(folder, training_data)\n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLKYddvbohMN"
      },
      "source": [
        "Calls the folder_to_array() functions and creates the training and testing data arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGp_F4EENuBM",
        "outputId": "f566f426-205c-4a3b-bd0a-3c9782b3b737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9600/9600 [00:06<00:00, 1590.11it/s]\n",
            "100%|██████████| 8960/8960 [00:05<00:00, 1757.30it/s]\n",
            "100%|██████████| 8960/8960 [00:05<00:00, 1774.59it/s]\n",
            "100%|██████████| 6464/6464 [00:03<00:00, 1638.74it/s]\n"
          ]
        }
      ],
      "source": [
        "nondemented_array = folder_to_array(\"/content/AugmentedAlzheimerDataset/NonDemented\", 0, 100)\n",
        "verymilddemented_array = folder_to_array(\"/content/AugmentedAlzheimerDataset/VeryMildDemented\", 1, 100)\n",
        "milddemented_array = folder_to_array(\"/content/AugmentedAlzheimerDataset/MildDemented\", 2, 100)\n",
        "moderatedemented_array = folder_to_array(\"/content/AugmentedAlzheimerDataset/ModerateDemented\", 3, 100)\n",
        "#creates the arrays from the unzipped Kaggle data located in the Colab\n",
        "\n",
        "train_size = int(min(len(nondemented_array), len(verymilddemented_array), len(milddemented_array), len(moderatedemented_array)))\n",
        "#the size of each sample size in the training batch is half of the minimum sample size\n",
        "\n",
        "train_size = int(train_size * 0.2) #try about ~20% of data in training instead\n",
        "\n",
        "training_data = np.concatenate((nondemented_array[0: train_size], verymilddemented_array[0: train_size], milddemented_array[0: train_size], moderatedemented_array[0: train_size]))\n",
        "testing_data = np.concatenate((nondemented_array[train_size:], verymilddemented_array[train_size:], milddemented_array[train_size:], moderatedemented_array[train_size:]))\n",
        "#creates the training data by concatenating all of the arrays of length train_size together, creates testing data by concatenating the rest of the data\n",
        "#generally we want a smaller portion of the data to be a part of the training dataset to avoid overfitting\n",
        "np.random.shuffle(training_data)\n",
        "np.random.shuffle(testing_data)\n",
        "#Shuffling and randomizing the data\n",
        "\n",
        "training_data = np.array(training_data)\n",
        "testing_data = np.array(testing_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1g4myGMoq2l"
      },
      "source": [
        "Adapted from Sentdex. The framework for the CNN, which consists of Convolutional layers for processing the image, Max pooling layers which downscales the 2D convolutional data into 1D, and the Fully connected layers, which are the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ahwxkZsIOOBH"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #optimize number of layers, hypertune parameters\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "        self.pool1 = nn.MaxPool2d((2, 2))\n",
        "        self.pool2 = nn.MaxPool2d((2, 2))\n",
        "        self.pool3 = nn.MaxPool2d((2, 2))\n",
        "        self.fc1 = nn.Linear(10368, 10368) #size fo the fully connected layer was determined by the size of the pictures, which are 100 x 100 pixels\n",
        "        self.fc2 = nn.Linear(10368, 4)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = x.flatten(start_dim=1) # flattening out\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "  \n",
        "net = Net().to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.00008) #optimize loss rate\n",
        "loss_function = nn.MSELoss()\n",
        "#net.forward(torch.randn(1, 1, 100, 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPpESEFxpNw7"
      },
      "source": [
        "Adapted from Sentdex. Transforms the numpy arrays into Pytorch tensors. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKfjXx61O2LU",
        "outputId": "e899fbce-80fe-42f8-ae7d-650cd22c48e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "training_picture = torch.Tensor([i[0] for i in training_data]).view(-1, 100, 100)\n",
        "training_picture = training_picture/255.0\n",
        "training_class = torch.Tensor([i[1] for i in training_data])\n",
        "\n",
        "testing_picture = torch.Tensor([i[0] for i in testing_data]).view(-1, 100, 100)\n",
        "testing_picture = testing_picture/255.0\n",
        "testing_class = torch.Tensor([i[1] for i in testing_data])\n",
        "\n",
        "#Warning: \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
        "#How to fix/make more efficent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6EA_5x7pS8f"
      },
      "source": [
        "Adapted from Sentdex. The training and testing function. fwd_pass is used to pass the training data through the CNN and adjust for loss. The fwd_test function finds a random set of data of size size to test the CNN on."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fwd_pass(training_data, testing_data, train=False):\n",
        "  if train:\n",
        "    net.zero_grad()\n",
        "  outputs = net(training_data)\n",
        "  matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, testing_data)]\n",
        "  acc = matches.count(True)/len(matches)\n",
        "  loss = loss_function(outputs, testing_data)\n",
        "\n",
        "  if train:\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  return acc, loss\n",
        "\n",
        "def fwd_test(size = 32):\n",
        "  random_start = np.random.randint(len(testing_picture) - size)\n",
        "  test_pic, test_class = testing_picture[random_start: random_start + size], testing_class[random_start: random_start + size]\n",
        "  with torch.no_grad():\n",
        "    val_acc, val_loss = fwd_pass(test_pic.view(-1, 1, 100, 100).to(device), test_class.to(device))\n",
        "  return val_acc, val_loss\n"
      ],
      "metadata": {
        "id": "B-FZL2LQPi0O"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted from Sentdex. Train() trains the CNN with the passed arguments and writes on a log file with all of the testing data. create_acc_loss_graph() creates a graph of the training data accuracy vs. the testing accuracy and the training loss vs. the testing loss."
      ],
      "metadata": {
        "id": "03039V2ksaYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(MODEL_NAME, BATCH_SIZE = 100, EPOCHS = 5, loss_rate = 0.00008):\n",
        "  net = Net().to(device)\n",
        "  optimizer = optim.Adam(net.parameters(), lr = loss_rate) #optimize loss rate\n",
        "  loss_function = nn.MSELoss()\n",
        "  with open(\"model.log\", \"a\") as f:\n",
        "    for epoch in range(EPOCHS):\n",
        "      for i in tqdm(range(0, len(training_picture), BATCH_SIZE)):\n",
        "          batch_pic = training_picture[i: i + BATCH_SIZE].view(-1, 1, 100, 100)\n",
        "          batch_class = training_class[i: i + BATCH_SIZE]\n",
        "          batch_pic, batch_class = batch_pic.to(device), batch_class.to(device)\n",
        "\n",
        "          acc, loss = fwd_pass(batch_pic, batch_class, True)\n",
        "          if i % 5 == 0:\n",
        "            val_acc, val_loss = fwd_test(size = 5000)\n",
        "            f.write(f\"{MODEL_NAME},{round(time.time(), 3)},{round(float(acc), 2)},{round(float(loss), 4)},{round(float(val_acc), 2)},{round(float(val_loss), 4)}\\n\")\n",
        "      print(f'Epoch {epoch} of {EPOCHS - 1}')\n",
        "  \n",
        "matplotlib.style.use(\"ggplot\")\n",
        "\n",
        "def create_acc_loss_graph(model_name, graph = True):\n",
        "  contents = open(\"model.log\", 'r').read().split('\\n')\n",
        "\n",
        "  times = []\n",
        "  accuracy = []\n",
        "  losses = []\n",
        "  val_accs = []\n",
        "  val_losses = []\n",
        "    \n",
        "  for c in contents:\n",
        "     if model_name in c:\n",
        "        name, timestamp, acc, loss, val_acc, val_loss = c.split(\",\")\n",
        "        times.append(float(timestamp))\n",
        "        accuracy.append(float(acc))\n",
        "        losses.append(float(loss))\n",
        "        val_accs.append(float(val_acc))\n",
        "        val_losses.append(float(val_loss))\n",
        "  \n",
        "  if graph:\n",
        "    fig = plt.figure()\n",
        "    ax1 = plt.subplot2grid((2, 1), (0, 0))\n",
        "    ax2 = plt.subplot2grid((2, 1), (1, 0), sharex = ax1)\n",
        "\n",
        "    ax1.plot(times, accuracy, label = \"Accuracy\")\n",
        "    ax1.plot(times, val_accs, label = \"Value Accuracy\")\n",
        "    ax1.legend(loc=2)\n",
        "\n",
        "    ax2.plot(times, losses, label = \"Loss\")\n",
        "    ax2.plot(times, val_losses, label = \"Value Losses\")\n",
        "    ax2.legend(loc=2)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  return times, accuracy, val_accs, losses, val_losses\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFdyY861T9OV",
        "outputId": "06d619fe-23e1-40ff-d1e2-023c5f4c8467"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model-1666927817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test_params() is used to test different parameters on its affect on accuracy for epochs, loss rate, and batch size. It outputs a graph of the testin variable vs. the accuracy. "
      ],
      "metadata": {
        "id": "J0m85ATzsy_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_params(BATCH_SIZE, EPOCHS, loss_rate):\n",
        "\n",
        "  if type(EPOCHS) == list and type(loss_rate) == float and type(BATCH_SIZE) == int:\n",
        "    fig = plt.figure()\n",
        "    ax = plt.subplot2grid((2, 1), (0, 0))\n",
        "    list_epochs = []\n",
        "    list_accuracy = []\n",
        "    for epoch in EPOCHS:\n",
        "      list_epochs.append(epoch)\n",
        "      MODEL_NAME = f\"model-{int(time.time())}\"\n",
        "      train(MODEL_NAME, BATCH_SIZE, epoch, loss_rate)\n",
        "      times, accuracy, val_accs, losses, val_losses = create_acc_loss_graph(MODEL_NAME, False)\n",
        "      list_ind = len(times) - int(len(times) * .1)\n",
        "      val_accuracy = val_accs[list_ind:]\n",
        "      val_average = sum(val_accuracy)/len(val_accuracy)\n",
        "      list_accuracy.append(val_average)\n",
        "    ax.plot(list_epochs, list_accuracy)\n",
        "    ax.set_xlabel(\"Epochs\")\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "  \n",
        "  if type(EPOCHS) == int and type(loss_rate) == list and type(BATCH_SIZE) == int:\n",
        "    fig = plt.figure()\n",
        "    ax = plt.subplot2grid((2, 1), (0, 0))\n",
        "    list_loss_rate = []\n",
        "    list_accuracy = []\n",
        "    for lr in loss_rate:\n",
        "      list_loss_rate.append(lr)\n",
        "      MODEL_NAME = f\"model-{int(time.time())}\"\n",
        "      train(MODEL_NAME, BATCH_SIZE, EPOCHS, lr)\n",
        "      times, accuracy, val_accs, losses, val_losses = create_acc_loss_graph(MODEL_NAME, False)\n",
        "      list_ind = len(times) - int(len(times) * .1)\n",
        "      val_accuracy = val_accs[list_ind:]\n",
        "      val_average = sum(val_accuracy)/len(val_accuracy)\n",
        "      print(val_average)\n",
        "      list_accuracy.append(val_average)\n",
        "    ax.plot(list_loss_rate, list_accuracy)\n",
        "    ax.set_xlabel(\"Loss Rates\")\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "  \n",
        "  if type(EPOCHS) == int and type(loss_rate) == int and type(BATCH_SIZE) == list:\n",
        "    fig = plt.figure()\n",
        "    ax = plt.subplot2grid((2, 1), (0, 0))\n",
        "    list_batch_size = []\n",
        "    list_accuracy = []\n",
        "    for size in BATCH_SIZE:\n",
        "      list_batch_size.append(lr)\n",
        "      MODEL_NAME = f\"model-{int(time.time())}\"\n",
        "      train(MODEL_NAME, size, EPOCHS, loss_rate)\n",
        "      times, accuracy, val_accs, losses, val_losses = create_acc_loss_graph(MODEL_NAME, False)\n",
        "      list_ind = len(times) - int(len(times) * .1)\n",
        "      val_accuracy = val_accs[list_ind:]\n",
        "      val_average = sum(val_accuracy)/len(val_accuracy)\n",
        "      list_accuracy.append(val_average)\n",
        "    ax.plot(list_batch_size, list_accuracy)\n",
        "    ax.set_xlabel(\"Batch Sizes\")\n",
        "    ax.set_ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "id": "sZhchpLbj2Hu"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_list = [1, 2, 3]\n",
        "test_params(100, epoch_list, 0.00006)"
      ],
      "metadata": {
        "id": "chbnWBzMtrYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-"
      ],
      "metadata": {
        "id": "nHBUMn3Stl8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-"
      ],
      "metadata": {
        "id": "6kVU45SVtlhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-"
      ],
      "metadata": {
        "id": "iHhK-FqFtcsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-"
      ],
      "metadata": {
        "id": "EEW66hkAtk-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-"
      ],
      "metadata": {
        "id": "W320hdQctgnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Old Functions Below For Reference:"
      ],
      "metadata": {
        "id": "LqGQY-pCtIUn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WQvy_gKSO4IM"
      },
      "outputs": [],
      "source": [
        "#Adapted from Sentdex\n",
        "\n",
        "testing_picture.to(device)\n",
        "testing_class.to(device)\n",
        "\n",
        "def train(net, BATCH_SIZE = 100, EPOCHS = 10): #optimize parametes\n",
        "  optimizer = optim.Adam(net.parameters(), lr = 0.00008) #optimize loss rate\n",
        "  loss_function = nn.MSELoss()\n",
        "  for epoch in range(EPOCHS):\n",
        "      for i in tqdm(range(0, len(training_picture), BATCH_SIZE)):\n",
        "          batch_pic = training_picture[i: i + BATCH_SIZE].view(-1, 1, 100, 100)\n",
        "          batch_class = training_class[i: i + BATCH_SIZE]\n",
        "          \n",
        "          batch_pic, batch_class = batch_pic.to(device), batch_class.to(device) \n",
        "          \n",
        "          net.zero_grad()\n",
        "          outputs = net(batch_pic)\n",
        "          loss = loss_function(outputs, batch_class)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      print(f'Epoch: {epoch}, Loss: {loss}')\n",
        "\n",
        "testing_picture = testing_picture[0:5000]\n",
        "testing_class = testing_class[0:5000]\n",
        "\n",
        "def test(net):\n",
        "  correct, total = 0, 0\n",
        "  with torch.no_grad():\n",
        "      for i in tqdm(range(len(testing_picture))):\n",
        "          real_class = torch.argmax(testing_class[i]).to(device)\n",
        "          net_out = net(testing_picture[i].view(-1, 1, 100, 100).to(device))[0]\n",
        "          predicted_class = torch.argmax(net_out)\n",
        "          #print(f'{predicted_class}, {real_class}')\n",
        "          if predicted_class == real_class:\n",
        "              correct += 1\n",
        "          total += 1\n",
        "  print(correct, total)\n",
        "  return(round(correct/total, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ilRryfmPfyz"
      },
      "outputs": [],
      "source": [
        "net = Net().to(device)\n",
        "train(net, BATCH_SIZE = 100, EPOCHS = 5)\n",
        "print(test(net))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLb9Fgjz4PtM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_rate_test1 = [0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
        "loss_rate_test2 = [0.00008, 0.0001, 0.00015, 0.0002, 0.00025]\n",
        "accuracy_list = []\n",
        "for loss in loss_rate_test2:\n",
        "  net1 = Net().to(device)\n",
        "  train(net1, BATCH_SIZE = 100, EPOCHS = 3, loss_rate = loss)\n",
        "  accuracy_list.append(test(net1))\n",
        "\n",
        "plt.plot(loss_rate_test2, accuracy_list)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Loss Rate\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}